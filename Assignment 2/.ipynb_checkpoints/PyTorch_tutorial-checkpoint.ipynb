{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXuuhJ2NPilg"
   },
   "source": [
    "# PyTorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ac8rTsQ6Rwiw"
   },
   "source": [
    "In this tutorial, we will go through the basics of PyTorch, training models on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAUaCTgDRGeS"
   },
   "source": [
    "Why PyTorch:\n",
    "\n",
    "- PyTorch \n",
    "\n",
    ">**+** Dynamic graphs run in a pythonic way, making it easier to understand what some piece of code is doing and to debug\n",
    "\n",
    ">**+** Offers a good amount of pretrained models and modules.\n",
    "\n",
    "> **-** It is still a young framework, so not as widely used as others\n",
    "\n",
    " \n",
    "\n",
    "- Keras\n",
    "\n",
    ">**\\+** Easiest framework to code simple models\n",
    "\n",
    ">**\\-** Lack of flexibility:  It is not made for models that use configurations that are not common\n",
    "\n",
    " \n",
    "\n",
    "- TensorFlow\n",
    "\n",
    ">**+** Framework usually used in industry, since it has TensorFlow serving, a tool to deploy models in production\n",
    "\n",
    ">**-** Static graph runs out of the python code, making it harder to debug\n",
    "\n",
    ">**-** Not well organized so far in terms of pre-coded layers and models (Tensorflow 2.0 should change that)\n",
    "\n",
    "\n",
    "**>** PyTorch ends up being a good option for research and for learning deep learning, since it is as flexible as TensorFlow, but easier to use for prototyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rANxEkHeW6rw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3AWWcWjmOnBB"
   },
   "source": [
    "## Tensor basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDClMW5TO4FW"
   },
   "source": [
    "PyTorch tensors are like numpy arrays, but that can be used with PyTorch modules and can be sent to GPUs. Several functions are similar to numpy functions, but several are not. Most tensor functions are listed in https://pytorch.org/docs/stable/torch.html#tensors or in https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "Tensor shapes:\n",
    "- For linear layers: Batch Size X Channels\n",
    "- For 2d Convolutional Layer: Batch Size X Channels X Height X Width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77v7wltOZLNT"
   },
   "source": [
    "#### Example of a few tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBW9DrUtXZ4Y"
   },
   "source": [
    "You can create tensors of different types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkm8XPy1QIIG"
   },
   "outputs": [],
   "source": [
    "x = torch.ones(6, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKqp6AB-XTgP"
   },
   "source": [
    "Use tensor.size() to get shape of tensor:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmaPXCp_W-5a"
   },
   "outputs": [],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXZTVkaRXLnL"
   },
   "source": [
    "Use tensor.view to reshape tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya44efFdXBKg"
   },
   "outputs": [],
   "source": [
    "print(x.view(3,3,2).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eB1QJ-ZXCdo"
   },
   "outputs": [],
   "source": [
    "print(torch.sum(x, dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9Gru0FhO5oH"
   },
   "source": [
    "#### Tensor devices and conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgvZgk0YZavS"
   },
   "source": [
    "Tensors can be converted back and forth from numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzSXf5yWZOzc"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(np.array([[1 , 2],[3, 4]]))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZrsxP3KZdG2"
   },
   "outputs": [],
   "source": [
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wnb0ubypZ1mE"
   },
   "source": [
    "Tensors can be sent back and forth from GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wZ3gZF-Z5j5"
   },
   "outputs": [],
   "source": [
    "x = x.cuda()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2IFUpCva5zM"
   },
   "outputs": [],
   "source": [
    "x = x.cpu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjKFFc_HZ7mF"
   },
   "source": [
    "Tensors should be on the same device as the model/module you run them on. So, to use GPU, you should have your input tensors stored on a GPU and your model stored on a GPU. For storing outputs of models or losses, it is better to transform them into numpy variables first. You can only convert to numpy tensors that are on a CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLHCnloiaQNT"
   },
   "outputs": [],
   "source": [
    "x = x.cuda().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v05ZOH5kOSK7"
   },
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5o_GLCdOZFT"
   },
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDydSlH3qVwD"
   },
   "source": [
    "The Dataset class in PyTorch is the one used to define data loading and transformations. For a custom dataset not offered by PyTorch, you will usually have to inherit from the dataset class to define how to load your data. More details here: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset. Examples of this are provided in the Assignment 2 notebook. An object of this class can be indexed like python lists to get a specific dataset example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPSOWuUJ7BBz"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root = './', download=True, train = True, \n",
    "                           transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "]))\n",
    "\n",
    "#using test set as validation set for practical reasons in the tutorial\n",
    "# please do not do this to evaluate models\n",
    "val_dataset = torchvision.datasets.MNIST(root = './', download=True, train = False, \n",
    "                           transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2v3RBnsW7lbz"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "\n",
    "plt.imshow(train_dataset[0][0][0,:,:])\n",
    "print(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFCdlLXWOb7x"
   },
   "source": [
    "#### Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwDTY5Xpplbm"
   },
   "source": [
    "PyTorch offers a few preprocessing functions for images (https://pytorch.org/docs/stable/torchvision/transforms.html). It contains both non-random transformations, for example resizing or normalizing images, and random transformations, for example random crops or random rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJUrWXs78Q92"
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.array(torchvision.transforms.RandomRotation(degrees = 25)(Image.fromarray(train_dataset[0][0][0,:,:].numpy()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsGPznZy_9LJ"
   },
   "outputs": [],
   "source": [
    "for image in torchvision.transforms.FiveCrop(size = 22)(Image.fromarray(train_dataset[0][0][0,:,:].numpy())):\n",
    "  plt.imshow(np.array(image))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8eykSX7OafI"
   },
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoIU0rUkqzxn"
   },
   "source": [
    "The DataLoader class handles how the dataset is sampled for training or testing. The main functions of it are handling the shuffling of the dataset, the batch size and the parallel loading of data. You will almost always directly use the provided class from PyTorch: (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMjeKK5c8531"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle = True, batch_size = 256, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 256, num_workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8a-P9v1DONq5"
   },
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZOdFHmhcSaa"
   },
   "source": [
    "We will create three models here to exemplify different ways of constructing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAPwHFSDb5G8"
   },
   "source": [
    "Models are derived classes of the torch.nn.Module class, and are usually composed of several modules. The nn package should contain all the important layers for deep learning: https://pytorch.org/docs/stable/nn.html . Some of these important layers are Linear, MaxPool2d, AvgPool2d, Conv2d, Dropout2d, BatchNorm2d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HapmC19Po8N_"
   },
   "source": [
    "#### Creating with Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xabtMq5QKmfH"
   },
   "source": [
    "The Sequential module (https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) is one way of creating models, when they are a simple sequence of other modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hv6m4kQaJhQn"
   },
   "outputs": [],
   "source": [
    "model1 = torch.nn.Sequential(torch.nn.Linear(in_features = 28*28, out_features = 100), torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(in_features = 100, out_features = 10))\n",
    "model1 = model1.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGH1_ACcpEzJ"
   },
   "source": [
    "#### Creating with Module class inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRo4HI2xeEXe"
   },
   "source": [
    "You can also inherit from the Module class to create a model. You should declare a forward function, which defines what feeding the model with an input does. The backward pass is defined by PyTorch automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPXx1De_LJvS"
   },
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.convolution_layer_1 = torch.nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpooling_layer = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        self.convolution_layer_2 = torch.nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 5)\n",
    "        self.fully_connected_layer = torch.nn.Linear(in_features = 256, out_features = 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpooling_layer(x)\n",
    "        x = self.convolution_layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpooling_layer(x)\n",
    "        \n",
    "        #flattening the tensor so that it can serve as input to a linear layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected_layer(x)\n",
    "        return x\n",
    "      \n",
    "model2 = ConvNet()\n",
    "model2 = model2.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNGvar75pAu_"
   },
   "source": [
    "#### Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7XEelUHn534"
   },
   "source": [
    "All weights are initialized using a good initialization rule. But you can also set your own rules using modules from torch.nn.init (https://pytorch.org/docs/master/nn.html#torch-nn-init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY1ZsV__n5kr"
   },
   "outputs": [],
   "source": [
    "torch.nn.init.xavier_normal_(model2.convolution_layer_1.weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VENBt6dypKSA"
   },
   "source": [
    "#### Creating with pre-defined models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mC3n8AemNj_K"
   },
   "source": [
    "PyTorch offers a few pre-built models with optional pretrained weights on ImageNet (https://pytorch.org/docs/stable/torchvision/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ya677gnZM3vO"
   },
   "outputs": [],
   "source": [
    "model3 = torchvision.models.resnet18(pretrained = True)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ce0ZYnTU9KWH"
   },
   "outputs": [],
   "source": [
    "print(model3.fc)\n",
    "print(model3.conv1)\n",
    "model3.fc = torch.nn.Linear(in_features = 512, out_features = 10)\n",
    "model3.avgpool = torch.nn.Sequential()\n",
    "model3 = model3.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ip4XamiuOupX"
   },
   "source": [
    "## Other declarations for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vl7HSw_VpRlu"
   },
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWAtoQqUsKqO"
   },
   "source": [
    "PyTorch has several different kinds of losses predefined (https://pytorch.org/docs/stable/nn.html#loss-functions). For this example, we will use CrossEntropyLoss. It is preferable to use the losses that receive logits instead of probabilities because they are numerically more stable. You should be careful to have a model output which matches what your loss expects as input. Note that the models defined in the Models section above do not have a Softmax output. Instead, we are going to use a loss function that does the softmax for us. Also, the CrossEntropyLoss receives classes as target, and not one-hot vectors. This means we do not need to change the labels from the dataset to feed it to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RC51DlIUunPK"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6j_BZlEpTL1"
   },
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GWQEka1usZd"
   },
   "source": [
    "PyTorch has several different kinds of optimizers predefined (https://pytorch.org/docs/stable/optim.html). You should provide a specific set of weights to each optimizer instance to specify which weights it should optimize. More details on the use of the optimizer will be presented in the training section of this tutorial.\n",
    "\n",
    "We will use the Adam optimizer since usually it is the optimizer that presents the fastest convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OHm0dUHwMkf"
   },
   "outputs": [],
   "source": [
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr = 0.01)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr = 0.0005)\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4nmuwPpOzeH"
   },
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PP6KLwoDw-MD"
   },
   "source": [
    "1) **Loops:** We will have two loops, one for epochs and one for batches\n",
    "\n",
    "2) **Model mode:** Remember to toggle train or eval mode\n",
    "\n",
    "3) **zero_grad:** PyTorch accumulates gradients by default. This means that in the rare cases we want to run backpropagation more than once for the same batch, it will remember the gradients for both backpropagations.  However, for every new batch, we want the gradients to have no influences from the gradients of the previous batch. So at the start of every batch iteration, we call the zero_grad() function. \n",
    "\n",
    "4) **backward:** To run backpropagation, we need to call the backward() function for the loss\n",
    "\n",
    "5) **step:** To update the parameters, we need to call the step function for the optimizer of those parameters\n",
    "\n",
    "6)  **Monitoring:**\n",
    "- We want to monitor a few metrics during training to be able to compare different models, check that the model is learning something and check if the model has converged. For this, in this tutorial we will print the training loss value. It is also important to follow the training and validation accuracy for every epoch. You could do this more frequently than every epoch, if needed.\n",
    "- TensorBoard, for TensorFlow, is an even better way for monitoring training. For PyTorch, you can use tensorboardX (https://github.com/lanpa/tensorboardX) to create TensorBoard files, and then use TensorBoard to visualize them.\n",
    "\n",
    "7)  **Memory leak:** Be careful not to store tensors from several different iterations, as this may cause memory leaks. Use .item() to convert a single-valued tensor to a python number, or .cpu().numpy() to convert a larger tensor to a numpy array before storing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_PB0WBg3t_H"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5): # 1)\n",
    "  \n",
    "    model1.train() # 2)\n",
    "    model2.train() # 2)\n",
    "    model3.train() # 2)\n",
    "    \n",
    "    losses1 = []\n",
    "    losses2 = []\n",
    "    losses3 = []\n",
    "    for images, targets in train_loader: # 1)\n",
    "      \n",
    "        optimizer1.zero_grad() # 3)\n",
    "        optimizer2.zero_grad() # 3)\n",
    "        optimizer3.zero_grad() # 3)\n",
    "        \n",
    "        #putting variables on GPU since model is on GPU\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        #running each model by adapting the imagees tensor to the expected input size of each model\n",
    "        out1 = model1(images.view(images.size(0), -1))\n",
    "        out2 = model2(images)\n",
    "        out3 = model3(images.expand(-1, 3, -1, -1))\n",
    "        \n",
    "        #calculating the losses with the defined criterion\n",
    "        loss1 = criterion(out1, targets)\n",
    "        loss2 = criterion(out2, targets)\n",
    "        loss3 = criterion(out3, targets)\n",
    "        \n",
    "        loss1.backward() # 4)\n",
    "        loss2.backward() # 4)\n",
    "        loss3.backward() # 4)\n",
    "        \n",
    "        optimizer1.step() # 5)\n",
    "        optimizer2.step() # 5)\n",
    "        optimizer3.step() # 5)\n",
    "        \n",
    "        losses1.append(loss1.item()) # 6) 7)\n",
    "        losses2.append(loss2.item()) # 6) 7)\n",
    "        losses3.append(loss3.item()) # 6) 7)\n",
    "        \n",
    "    print('Epoch ' + str(epoch)) # 6)\n",
    "    print('loss1: ' + str(np.mean(losses1))) # 6)\n",
    "    print('loss2: ' + str(np.mean(losses2))) # 6)\n",
    "    print('loss3: ' + str(np.mean(losses3))) # 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eeN3NzWPmoa"
   },
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-L079YjEzNG7"
   },
   "source": [
    "Evaluating the model has a similar structure to training the model, but there is no need for gradients and optimizers, and you should toggle the eval mode of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuVJ8icd9ZTX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#turning off gradients will make model run slightly faster\n",
    "with torch.no_grad():\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "\n",
    "    n_corrects1 = 0\n",
    "    n_corrects2 = 0\n",
    "    n_corrects3 = 0\n",
    "    for images, targets in val_loader:\n",
    "\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        out1 = model1(images.view(images.size(0), -1))\n",
    "        out2 = model2(images)\n",
    "        out3 = model3(images.expand(-1, 3, -1, -1))\n",
    "        \n",
    "        # Counting how many correct predictions were made for this batch\n",
    "        # to get the prediction of each model, find the index \n",
    "        # of the maximum logit in each batch example\n",
    "        n_corrects1 += torch.sum(torch.argmax(out1, dim = 1)==targets).item()\n",
    "        n_corrects2 += torch.sum(torch.argmax(out2, dim = 1)==targets).item()\n",
    "        n_corrects3 += torch.sum(torch.argmax(out3, dim = 1)==targets).item()\n",
    "\n",
    "    print('accuracy1: ' + str(n_corrects1/len(val_dataset)))\n",
    "    print('accuracy2: ' + str(n_corrects2/len(val_dataset)))\n",
    "    print('accuracy3: ' + str(n_corrects3/len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMbJTKvc9KWw"
   },
   "source": [
    "Now we combine training and evaluation in the same cell to follow validation and training during training. The code is just a combined copy and paste from the two previous code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IN9SwFve9KWy"
   },
   "outputs": [],
   "source": [
    "#continuing training but now monitoring accuracy for training and validation\n",
    "for epoch in range(10): \n",
    "    model2.train() \n",
    "    model3.train() \n",
    "    \n",
    "    losses1 = []\n",
    "    losses2 = []\n",
    "    losses3 = []\n",
    "    \n",
    "    #training\n",
    "    for images, targets in train_loader: \n",
    "      \n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad() \n",
    "        optimizer3.zero_grad() \n",
    "        \n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        out1 = model1(images.view(images.size(0), -1))\n",
    "        out2 = model2(images)\n",
    "        out3 = model3(images.expand(-1, 3, -1, -1))\n",
    "        \n",
    "\n",
    "        loss1 = criterion(out1, targets)\n",
    "        loss2 = criterion(out2, targets)\n",
    "        loss3 = criterion(out3, targets)\n",
    "        \n",
    "        loss1.backward() \n",
    "        loss2.backward() \n",
    "        loss3.backward() \n",
    "        \n",
    "        optimizer1.step() \n",
    "        optimizer2.step() \n",
    "        optimizer3.step() \n",
    "        \n",
    "        losses1.append(loss1.item()) \n",
    "        losses2.append(loss2.item()) \n",
    "        losses3.append(loss3.item()) \n",
    "        \n",
    "    print('Epoch ' + str(epoch)) \n",
    "    print('loss1: ' + str(np.mean(losses1))) \n",
    "    print('loss2: ' + str(np.mean(losses2))) \n",
    "    print('loss3: ' + str(np.mean(losses3))) \n",
    "    \n",
    "    #accuracy for validation\n",
    "    with torch.no_grad():\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "        model3.eval()\n",
    "\n",
    "        n_corrects1 = 0\n",
    "        n_corrects2 = 0\n",
    "        n_corrects3 = 0\n",
    "        for images, targets in val_loader:\n",
    "\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            out1 = model1(images.view(images.size(0), -1))\n",
    "            out2 = model2(images)\n",
    "            out3 = model3(images.expand(-1, 3, -1, -1))\n",
    "\n",
    "            n_corrects1 += torch.sum(torch.argmax(out1, dim = 1)==targets).item()\n",
    "            n_corrects2 += torch.sum(torch.argmax(out2, dim = 1)==targets).item()\n",
    "            n_corrects3 += torch.sum(torch.argmax(out3, dim = 1)==targets).item()\n",
    "        \n",
    "        print('Validation:')\n",
    "        print('accuracy1: ' + str(n_corrects1/len(val_dataset)))\n",
    "        print('accuracy2: ' + str(n_corrects2/len(val_dataset)))\n",
    "        print('accuracy3: ' + str(n_corrects3/len(val_dataset)))\n",
    "        \n",
    "    #accuracy for training\n",
    "    with torch.no_grad():\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "        model3.eval()\n",
    "\n",
    "        n_corrects1 = 0\n",
    "        n_corrects2 = 0\n",
    "        n_corrects3 = 0\n",
    "        for images, targets in train_loader:\n",
    "\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            out1 = model1(images.view(images.size(0), -1))\n",
    "            out2 = model2(images)\n",
    "            out3 = model3(images.expand(-1, 3, -1, -1))\n",
    "\n",
    "            n_corrects1 += torch.sum(torch.argmax(out1, dim = 1)==targets).item()\n",
    "            n_corrects2 += torch.sum(torch.argmax(out2, dim = 1)==targets).item()\n",
    "            n_corrects3 += torch.sum(torch.argmax(out3, dim = 1)==targets).item()\n",
    "        print('Training:')\n",
    "        print('accuracy1: ' + str(n_corrects1/len(train_dataset)))\n",
    "        print('accuracy2: ' + str(n_corrects2/len(train_dataset)))\n",
    "        print('accuracy3: ' + str(n_corrects3/len(train_dataset)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "env_dir",
   "language": "python",
   "name": "env_dir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
