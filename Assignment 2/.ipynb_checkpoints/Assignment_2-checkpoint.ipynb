{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "You are expected to complete this notebook with lines of code, plots and texts. You will need to create new cells with original code or text for your analyses and explanations. Explain what you do and analyze your results. This assignment has a total of 100 points.\n",
    "\n",
    "Using Canvas, you will deliver the notebook file (.ipynb) with cells executed and outputs visible.\n",
    "- You should use PyTorch 1.0 or later as your deep learning framework. If you need to import a different package than the ones already imported, ask the TA if you can do it.\n",
    "- No other data than the dataset variables provided should be used, and training, validation and testing splits should be the same as the ones provided.\n",
    "- The cell outputs present in your delivered notebook should be reproducible by us by running your notebook cells in order.\n",
    "- All code must be your own work. Code cannot be copied from another source or student. You may copy code from cells that were pre-defined in this notebook if you think it is useful for use in another part of the notebook.\n",
    "- All images must be generated from data generated in your code. Do NOT import/display images generated outside your code.\n",
    "- Your analysis must be your own, but if you quote text or equations from another source make sure to cite the reference.\n",
    "- It is assumed that PyTorch is already installed according to the CADE or the COLAB tutorial.\n",
    "\n",
    "Other notes:\n",
    "- Cells should be run in order, using Shift+Enter.\n",
    "- Read all the provided code cells and its comments, as it contains variables and information that you may need to use to complete the notebook.\n",
    "- To create a text cell, create it with the \"+\" button and change its type from \"Code\" to \"Markdown\" using the top menu. To modify a text cell, double click on it.\n",
    "- If you are interested, you can check detail on formatting markdown text here: https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\n",
    "- The accuracies provided as required for each question are there to make sure you work enough on each model to get a good result. Part of the grade is based on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips for training deep learning models:\n",
    "- Since the datasets being used here are small, you are probably going to have to use early stopping as a way of preventing overfitting. This means you will have to save models in the middle of training. One of the ways to save models on memory is to do a deep copy of it (using ```copy.deepcopy``` ). \n",
    "- It is also recommended to frequently (at least once every epoch) print the loss of the model and the score it is getting at its intended task, to follow if the model is learning something and if it is still improving. Usually you will need somewhere between 1 and 15 epochs for your model to get the required accuracy in this assignment.\n",
    "- To search for the best hyperparameters for your model, it is usually better to start searching in a logarithmic scale. Usually powers of 2 or 10 are used. \n",
    "- In https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2, different optimal learning rates for different optimizers were found for a different task. This could help in your search of optimal learning rate. For this assignment, you will probably get the best results by using Adam and searching for the best learning rate in the range of good learning rates provided in the cited page, which for Adam is from 0.00005 to 0.01.\n",
    "- Batch size seems to have a smaller impact than learning rate in the results. It should be enough if you test batch sizes between 8 and 32.\n",
    "- We assume a GPU of at least 4GB of memory is available. If you want to try running the assignment with a GPU that has less than that, you can try changing the argument passed when calling the ```define_gpu_to_use``` function.  If you are getting out-of-memory errors for the GPU, you may want to check what is occupying the GPU memory by using the command ```!nvidia-smi```, which gives a report of the use of the GPU. \n",
    "- For some of the questions, it might be useful for you to understand what the resnet18 PyTorch model is doing. You can have access to its source code here: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py . The most important part to understand should be the ```forward``` function from the ```ResNet``` class. It might also be useful to print PyTorch models using ```print(model)```. This should give you a list of all the layers present in the model.\n",
    "- Between CADE and COLAB (i.e. Google Colaboratory), CADE is probably the best option for running this assignment, since it seems to be about 50% faster than COLAB and files are not erased when resetting sessions. CADE has a small disk quota for the home directory, so it might be necessary, depending on how much your home directory is already occupied, to store the virtual environment inside a folder in ```/scratch/tmp/```. For CADE, datasets are already downloaded and stored in a scratch folder accessible to everyone.\n",
    "- If you are using Google Colaboratory, it might be interesting to store the datasets on your Google Drive to prevent having to download it every time you restart your sessions. For that, you will probably need to add the line ```drive.mount('/content/gdrive')``` and change the ```pre_folder``` variable to ```'gdrive/My Drive'```. This was not tested, so some adjustments may be needed.\n",
    "- There are a few PyTorch details not to forget:\n",
    "    - Remember to toggle train/eval mode for your model\n",
    "    - Remember to reset the gradients with ```zero_grad()``` before each call to ```backward()```\n",
    "    - Remember to check if the loss you are using receives logits or probabilities, and adapt your model output accordingly.\n",
    "    - Remember to reinstantiate your model every time you are starting a new training, so that weights are reset.\n",
    "    - Remember to pass to the optimizer the set of parameters for the model you want to train.\n",
    "- Starting training from a pretrained model instead of starting it from scratch usually helps to get a better final result. For the exercises that use the resnet18 model from PyTorch, you can start training with the model pretrained on ImageNet that is provided by PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing and loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /home/u0579755/env_dir/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn in /home/u0579755/env_dir/lib/python3.6/site-packages (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/u0579755/env_dir/lib/python3.6/site-packages (from scikit-learn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/u0579755/env_dir/lib/python3.6/site-packages (from scikit-learn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q kaggle\n",
    "!pip3 install pydicom\n",
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import tarfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining folders where data should be saved/loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking what kind of system you are using\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  from google.colab import files\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "try:\n",
    "    hostname = !hostname\n",
    "    if 'lab' in hostname[0] and '.eng.utah.edu' in hostname[0]:\n",
    "        IN_CADE = True\n",
    "    else:\n",
    "        IN_CADE = False\n",
    "except:\n",
    "    IN_CADE = False\n",
    "\n",
    "assert(not IN_CADE or not IN_COLAB)\n",
    "\n",
    "#defining the folders where datasets will be, depending on the system\n",
    "machine_being_used = 'cade' if IN_CADE else ('colab' if IN_COLAB else 'other')\n",
    "pre_folder = '/scratch/tmp/' if machine_being_used == 'cade' else './'\n",
    "pneumonia_dataset_folder = pre_folder + 'deep_learning_datasets_ECE_6960_013/kaggle_pneumonia'\n",
    "xray14_dataset_folder = pre_folder + 'deep_learning_datasets_ECE_6960_013/chestxray14'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the GPU to use and reserving its memory for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this function you set the value of the environment variable CUDA_VISIBLE_DEVICES\n",
    "# to set which GPU to use\n",
    "# it also reserves this amount of memory for your exclusive use. This might be important for \n",
    "# not having other people using the resources you need in shared systems\n",
    "# the homework was tested in a GPU with 4GB of memory, and running this function will require at least\n",
    "# as much\n",
    "# if you want to test in a GPU with less memory, you can call this function\n",
    "# with the argument minimum_memory_mb specifying how much memory from the GPU you want to reserve\n",
    "def define_gpu_to_use(minimum_memory_mb = 3800):\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader\n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        if free_memory>minimum_memory_mb-500:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' +str(minimum_memory_mb) + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-500)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU already assigned before: 0\n"
     ]
    }
   ],
   "source": [
    "#setting the gpu that will be used, testing if it has enough available memory, and reserving the needed memory\n",
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions that are used internally in both exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a pre-transformation class that is used to preprocess the images\n",
    "# this class receives a Pillow Image, and crops it so that it has a 1:1 aspect\n",
    "# ratio (i.e. a square). It chooses the biggest square possible that fits in the image\n",
    "# and centers it.\n",
    "# this is important for medical datasets, since a lot of them have images\n",
    "# with different aspect ratios and this is one way of dealing with it and \n",
    "# standardizing the inputs\n",
    "class CropBiggestCenteredInscribedSquare(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        longer_side = min(tensor.size)\n",
    "        horizontal_padding = (longer_side - tensor.size[0]) / 2\n",
    "        vertical_padding = (longer_side - tensor.size[1]) / 2\n",
    "        return tensor.crop(\n",
    "            (\n",
    "                -horizontal_padding,\n",
    "                -vertical_padding,\n",
    "                tensor.size[0] + horizontal_padding,\n",
    "                tensor.size[1] + vertical_padding\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split can be 'train', 'val', and 'test'\n",
    "#this is the function that splits a dataset into training, validation and testing set\n",
    "#We are using a split of 60%-20%-20%, for train-val-test, respectively\n",
    "#this function is used internally to the defined dataset classes\n",
    "# In medical datasets possibly containing more than one example for the same subject/patient,\n",
    "# this function should be applied to the list of patients/subjects, and not to the list of examples\n",
    "# since in a real-world application you will not find the same subject/patient as your training data had,\n",
    "# and therefore you should measure how well your model is doing in the same settings\n",
    "def get_split(array_to_split, split):\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(array_to_split)\n",
    "    np.random.seed()\n",
    "    if split == 'train':\n",
    "        array_to_split = array_to_split[:int(len(array_to_split)*0.6)]\n",
    "    elif split == 'val':\n",
    "        array_to_split = array_to_split[int(len(array_to_split)*0.6):int(len(array_to_split)*0.8)]\n",
    "    elif split == 'test':\n",
    "        array_to_split = array_to_split[int(len(array_to_split)*0.8):]\n",
    "    return array_to_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions that might be useful for you in both exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to \n",
    "# count how many parameters (learnable parameters, more specifically)\n",
    "# there are in a pytorch model\n",
    "def count_number_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: ChestXray14 Dataset\n",
    "**(56 points total)**\n",
    ">### Brief explanation of the dataset\n",
    "> In this exercise we will use the ChestXray14 dataset. This dataset contains more than 100,000 frontal chest x-rays and labels for 14 different conditions. These labels were extracted from radiologists' reports associated with each image using natural language processing techniques. It was released at the end of 2017 and until the beginning of 2019, when CheXpert (https://stanfordmlgroup.github.io/competitions/chexpert/) and MIMIC-CXR (https://physionet.nlm.nih.gov/physiobank/database/mimiccxr/) were released, it was the best source for a large amount of training data for models using chest x-rays. These other two mentioned datasets contain about 300,000 images each, and contain x-ray studies with both the lateral and the frontal view. Using both views has been shown to improve results in deep learning models (https://arxiv.org/abs/1804.07839). More information about the ChestXray14 dataset can be found here: https://stanfordmlgroup.github.io/projects/chexnet/. The dataset was also criticized regarding the choice of label classes, among other things. More information about this can be found in these two blog posts by Luke Oakden-Rayner: https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/ and https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/. \n",
    "\n",
    "We will be using only a subset of this dataset, 14,999 images total, so that we can have smaller loading and training times. The labels of this dataset follow a multi-label structure, which means that more than one label can be present for a single image, and images with no anomaly have no label associated with them.\n",
    "\n",
    "**Important:** Please download the file **Data_Entry_2017.csv** from https://nihcc.app.box.com/v/ChestXray-NIHCC and put it in the same directory as this notebook. If you are using Google Colaboratory, use the python command ```files.upload()``` below to upload the file. Same thing for the file **image_names_chestxray14.csv**, provided with the assignment.\n",
    "\n",
    "For this exercise, we will use the AUC (also called AUROC) metric to evaluate models. The AUC metric is defined as the area under the Receiver Operating Characteristic (ROC) curve. The AUC is a score between 0 and 1. An AUC of 0.5 is what a model giving random outputs can reach. The higher the AUC, the better the model is. The ROC curve is frequently used for medical tasks since it tries to measure the trade-off of a model in terms of false positives and false negatives (sensitivity and specificity, to be more precise), and a lot of medical tasks tries to avoid either false negatives or false positives. ROC is also insensitive to imbalanced datasets, which is important in this exercise, since it is a highly imbalanced dataset, as we will see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the dataset and defining loading and processing  steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Google Colaboratory, use the next line to upload the Dataset_Entry_2017.csv file\n",
    "# else put it in the same folder as this notebook\n",
    "if machine_being_used == 'colab':\n",
    "    files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Google Colaboratory, use the next line to upload the image_names_chestxray14.csv file\n",
    "# else put it in the same folder as this notebook\n",
    "if machine_being_used == 'colab':\n",
    "    files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download part of the dataset if it was not downloaded yet\n",
    "#downloading it to the xray14_dataset_folder folder\n",
    "\n",
    "#function to report how much has been downloaded so far\n",
    "def report_hook(count_so_far, block_size, total_size):\n",
    "    current_percentage = (count_so_far * block_size * 100 // total_size)\n",
    "    previous_percentage = ((count_so_far - 1) * block_size * 100 // total_size)\n",
    "    if current_percentage != previous_percentage:\n",
    "        sys.stdout.write('\\r' + str((count_so_far * block_size * 100 // total_size)) + '% of download completed')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "if xray14_dataset_folder != '/scratch/tmp/deep_learning_datasets_ECE_6960_013/chestxray14':\n",
    "    os.makedirs(xray14_dataset_folder, exist_ok=True)\n",
    "    from urllib.request import urlretrieve\n",
    "    destination_file = xray14_dataset_folder + '/images_4.tar.gz'\n",
    "    link = 'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz'\n",
    "    if not os.path.isfile(destination_file):\n",
    "        urlretrieve(link, destination_file, reporthook = report_hook)\n",
    "\n",
    "    destination_file = xray14_dataset_folder + '/images_1.tar.gz'\n",
    "    link = 'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz'\n",
    "    if not os.path.isfile(destination_file):\n",
    "        urlretrieve(link, destination_file, reporthook = report_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xray14_dataset_folder != '/scratch/tmp/deep_learning_datasets_ECE_6960_013/chestxray14':\n",
    "    #extract the downloaded files\n",
    "    destination_file = xray14_dataset_folder + '/images_4.tar.gz'\n",
    "    tar = tarfile.open(destination_file, \"r:gz\")\n",
    "    tar.extractall(path = xray14_dataset_folder)\n",
    "    tar.close()\n",
    "    destination_file = xray14_dataset_folder + '/images_1.tar.gz'\n",
    "    tar = tarfile.open(destination_file, \"r:gz\")\n",
    "    tar.extractall(path = xray14_dataset_folder)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pytorch dataset class\n",
    "# it contains the data reading, indexing and preprocessing for the chestxray14 dataset\n",
    "class Chestxray14Dataset(Dataset):\n",
    "    #split can be 'train', 'val', and 'test'\n",
    "    def __init__(self, path_dataset_folder, split = 'train'):\n",
    "        self.path_image_folder = path_dataset_folder + '/images'\n",
    "        \n",
    "        #get the filenames of all images in the dataset\n",
    "        all_images_list = pd.read_csv('image_names_chestxray14.csv')\n",
    "\n",
    "        #read the labels file, that should be placed in the same folder as this notebook\n",
    "        label_file = pd.read_csv('./Data_Entry_2017.csv')\n",
    "        #merging labels and image information\n",
    "        examples_to_use = pd.merge(all_images_list, label_file)\n",
    "        \n",
    "        #this is the name of all the labels possible in the dataset\n",
    "        # when getting a dataset item, labels will be part of an array of 14 elements, and these \n",
    "        #elements will be ordered following the order of this self.set_of_finding_labels list\n",
    "        self.set_of_finding_labels = ['Atelectasis', 'Cardiomegaly','Effusion',  'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', \n",
    "'Consolidation', 'Edema', 'Emphysema', 'Fibrosis','Pleural_Thickening', 'Hernia' ]\n",
    "        \n",
    "        # read labels from the label file\n",
    "        examples_to_use['Finding Labels'] = examples_to_use['Finding Labels'].str.split(pat = '|')\n",
    "        examples_to_use['Finding Labels'] = examples_to_use['Finding Labels'].apply(list).to_frame(name='Finding Labels')\n",
    "        for finding_label in self.set_of_finding_labels:\n",
    "            examples_to_use[finding_label] = examples_to_use.apply(lambda x: int(finding_label in x['Finding Labels']), axis=1)\n",
    "        \n",
    "        #getting the list of all patient ids present in the dataset, to split into\n",
    "        # training, validation and testing by patient id, and not by list of examples\n",
    "        patient_ids = pd.unique(examples_to_use['Patient ID'])\n",
    "        patient_ids = pd.DataFrame(get_split(patient_ids, split), columns = ['Patient ID'])\n",
    "        \n",
    "        #filtering the examples to only use the ones that have the chosen patient ids\n",
    "        examples_to_use = pd.merge(patient_ids,examples_to_use)\n",
    "        \n",
    "        \n",
    "        examples_to_use = examples_to_use[['Image Index'] + self.set_of_finding_labels]\n",
    "        self.image_list = examples_to_use['Image Index'].values\n",
    "        self.targets = examples_to_use[self.set_of_finding_labels].values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #defining the transformations to do to the images before feeding it to the deep learning model\n",
    "        #these include cropping it to a square, resizing it to the usual ImageNet used size, transform it into a pytorch\n",
    "        # tensor, and normalizing it using the ImageNet dataset average and standard deviation per channel\n",
    "        set_of_transforms = transforms.Compose(\n",
    "        [CropBiggestCenteredInscribedSquare(),\n",
    "         transforms.Resize(224),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "        image_to_return = set_of_transforms(Image.open(self.path_image_folder + '/' + self.image_list[index]).convert('RGB'))\n",
    "        \n",
    "        #the first element of the returned elements is an image stored in a pytorch tensor\n",
    "        # the second element is a set of 14 zeros or ones specifying the target labels for that image, \n",
    "        #following the order specified in the self.set_of_finding_labels variable\n",
    "        return image_to_return, torch.FloatTensor(self.targets[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    #use this function to get the ordered names of the labels returned by the __getitem__ function\n",
    "    def get_labels_name(self):\n",
    "        return self.set_of_finding_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the variables that you should use as datasets for Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the datasets to be used in exercise 1\n",
    "train_dataset_ex1 = Chestxray14Dataset(xray14_dataset_folder)\n",
    "val_dataset_ex1 = Chestxray14Dataset(xray14_dataset_folder, split = 'val')\n",
    "test_dataset_ex1 = Chestxray14Dataset(xray14_dataset_folder, split = 'test')\n",
    "\n",
    "# if any of the following asserts fail, please contact the TA\n",
    "assert(len(train_dataset_ex1) == 8837)\n",
    "assert(len(val_dataset_ex1) == 2924)\n",
    "assert(len(test_dataset_ex1) == 3238)\n",
    "assert(np.sum(train_dataset_ex1.targets)==5893)\n",
    "assert(np.sum(train_dataset_ex1.targets[:,7])==404)\n",
    "assert(np.sum(val_dataset_ex1.targets)==1810)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short visualization of the resulting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive examples for each class in the training set: \n",
      "\n",
      "Atelectasis: 9.99%,\n",
      "Cardiomegaly: 2.59%,\n",
      "Effusion: 10.97%,\n",
      "Infiltration: 14.20%,\n",
      "Mass: 4.35%,\n",
      "Nodule: 5.77%,\n",
      "Pneumonia: 1.01%,\n",
      "Pneumothorax: 4.57%,\n",
      "Consolidation: 3.45%,\n",
      "Edema: 1.56%,\n",
      "Emphysema: 2.43%,\n",
      "Fibrosis: 2.41%,\n",
      "Pleural_Thickening: 3.02%,\n",
      "Hernia: 0.36%\n",
      "\n",
      "\n",
      "Showing one example from the dataset:\n",
      "\n",
      "Atelectasis: 1.0,\n",
      "Cardiomegaly: 0.0,\n",
      "Effusion: 0.0,\n",
      "Infiltration: 0.0,\n",
      "Mass: 0.0,\n",
      "Nodule: 0.0,\n",
      "Pneumonia: 0.0,\n",
      "Pneumothorax: 0.0,\n",
      "Consolidation: 1.0,\n",
      "Edema: 0.0,\n",
      "Emphysema: 0.0,\n",
      "Fibrosis: 0.0,\n",
      "Pleural_Thickening: 0.0,\n",
      "Hernia: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def join_str_array_to_labels(str_array,labels):\n",
    "    return ','.join(['\\n{}: {}'.format(\n",
    "                                          labels[index_element], \n",
    "                                          str_array_element\n",
    "                                        ) \n",
    "                for index_element, str_array_element in enumerate(str_array)])\n",
    "\n",
    "#show how unbalanced dataset is\n",
    "frequencies = np.sum(train_dataset_ex1.targets, axis = 0)/len(train_dataset_ex1)\n",
    "text_frequencies = ['{:.2f}%'.format(frequency*100) for frequency in frequencies]                    \n",
    "print('Percentage of positive examples for each class in the training set: ')\n",
    "print(join_str_array_to_labels(text_frequencies, train_dataset_ex1.get_labels_name()))\n",
    "\n",
    "#plot a few images\n",
    "print('\\n\\nShowing one example from the dataset:')\n",
    "plt.imshow(train_dataset_ex1[1][0].cpu().numpy()[0,:,:], cmap = 'gray')\n",
    "print(join_str_array_to_labels(train_dataset_ex1[1][1],train_dataset_ex1.get_labels_name()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a scoring function for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function that calculates auc from a pair of arrays\n",
    "def auroc(logits_predicted, target):\n",
    "    series0, series1, _ = roc_curve(target, logits_predicted)\n",
    "    return auc(series0, series1)\n",
    "\n",
    "# defining the function that calculates the AUC score for exercise 1\n",
    "# one of the inputs should be a model with which inference is made\n",
    "# the model should have one array with 14 elements as output, and each output should be a score\n",
    "# the highest this score is, the highest the probability of this class being present in the image\n",
    "# the other input is a pytorch data loader for whatever set of data for which you want to get a score\n",
    "def get_score_model_chestxray_binary_model(model, data_loader):\n",
    "    #toggle model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    #turn off gradients since they will not be used here\n",
    "    # this is to make the inference faster\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        logits_predicted = np.zeros([0, 14])\n",
    "        targets = np.zeros([0, 14])\n",
    "        #run through several batches, does inference for each and store inference results\n",
    "        # and store both target labels and inferenced scores \n",
    "        for image, target in data_loader:\n",
    "            image = image.cuda()\n",
    "            logit_predicted = model(image)\n",
    "            logits_predicted = np.concatenate((logits_predicted, logit_predicted.cpu().detach().numpy()), axis = 0)\n",
    "            targets = np.concatenate((targets, target.cpu().detach().numpy()), axis = 0)\n",
    "            \n",
    "    #returns a list of scores, one for each of the labels\n",
    "    return [auroc(logits_predicted[:,i], targets[:,i]) for i in range(14)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1.1 (22 points)**: Modify the resnet18 model provided in the torchvision package from PyTorch (https://pytorch.org/docs/stable/torchvision/models.html#id3) to output 14 binary classifiers, and train it on the ChestXray14 dataset. Justify your choice of loss function. Get an AUC of at least 0.725 on the validation set. You should average the AUC of the 14 classes to get a single AUC score. After getting the desired accuracy, test your best model on the test set, and specify for which anomaly/label your model got its best score and for which anomaly/label your model got its worst score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-5674eb93bebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replacement module for fully connected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Wanted sigmoid to be part of layer so output is values between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mFullyConnectedReplacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFullyConnectedReplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "# Replacement module for fully connected layer\n",
    "# Wanted sigmoid to be part of layer so output is values between 0 and 1\n",
    "class FullyConnectedReplacement(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedReplacement, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features = 512, out_features = 14)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# Get data loaders \n",
    "b_size = 15\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_ex1, shuffle = True, batch_size = b_size, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset_ex1, batch_size = b_size, num_workers = 8)\n",
    "\n",
    "# Get resnet model and change the fc layer to output 14 predictions\n",
    "# Send model to GPU\n",
    "resnet_model = models.resnet18(pretrained = True)\n",
    "resnet_model.fc = FullyConnectedReplacement()\n",
    "resnet_model = resnet_model.cuda()\n",
    "\n",
    "# Define Loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training\n",
    "val_scores = []\n",
    "train_scores = []\n",
    "number_of_epochs = 10\n",
    "target_score = 0.725\n",
    "best_score = 0\n",
    "best_model = copy.deepcopy(resnet_model)\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    \n",
    "    # Toggle to training mode\n",
    "    resnet_model.train()\n",
    "\n",
    "    losses = []\n",
    "    for images, targets in train_loader:\n",
    "        # Zero out optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        # Get model prediction\n",
    "        out = resnet_model(images)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, targets)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track losss\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # Print mean loss for this epoch\n",
    "    print('Loss: ' + str(np.mean(losses)))\n",
    "    \n",
    "    # Get training data accuracy\n",
    "    train_score = get_score_model_chestxray_binary_model(resnet_model, train_loader)\n",
    "    mean_train_score = np.mean(train_score)\n",
    "    print('Trainig Score: ' + str(mean_train_score))\n",
    "    train_scores.append(mean_train_score)\n",
    "    \n",
    "    # Get validation data accuracy\n",
    "    val_score = get_score_model_chestxray_binary_model(resnet_model, val_loader)\n",
    "    mean_val_score = np.mean(val_score)\n",
    "    print('Validation Score: ' + str(mean_val_score))\n",
    "    val_scores.append(mean_val_score)\n",
    "    \n",
    "    # Save Best Model\n",
    "    if mean_val_score > target_score and mean_val_score > best_score:\n",
    "        best_score = mean_val_score\n",
    "        best_model = copy.deepcopy(resnet_model)\n",
    "        print('New Best Model Saved!')\n",
    "    \n",
    "# Plot Training and Validation AUC Score vs Epoch Number\n",
    "plt.plot(range(number_of_epochs), train_scores, 'b', range(number_of_epochs), val_scores, 'r')\n",
    "plt.title('AUC Scores Question 1.1')\n",
    "plt.legend(['Training Data', 'Validation Data'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions on Test Dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_ex1, batch_size = b_size, num_workers = 8)\n",
    "auc_score_test = get_score_model_chestxray_binary_model(best_model, test_loader)\n",
    "print('Conditions are Scores')\n",
    "print(join_str_array_to_labels(auc_score_test, test_dataset_ex1.get_labels_name()))\n",
    "\n",
    "print('\\nMax Score: ' + str(max(auc_score_test)))\n",
    "print('Min Score: ' + str(min(auc_score_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for Question 1.1\n",
    "\n",
    "For this question I updated the last layer of the ResNet model to output 14 values followed by a sigmoid to squash the values between 0 and 1. I used the BCELoss function. I chose this function because it uses the binary cross entropy loss which treats each label as an independent binary classifier. In addition the binary cross entropy loss punishes predictions that are confident and wrong; so false positives and false negatives will result in higher loss. Which seems particularly important for medical data.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for Question 1.1\n",
    "The anomaly with the best score is Cardiomegaly and the the anomaly with the worst score is Emphysema.\n",
    "\n",
    "The final model used was saved in Epoch 3. The hyperparameters are epochs = 4 (0 indexed), batch_size = 15, and learning_rate = 0.0005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 1.2 (34 points)**: Build a model of your own design with a maximum of 500,000 parameters that reaches at least 0.67  AUC on the validation set when trained from scratch. You should average the AUC of the 14 classes to get a single AUC score. Besides getting a good score, you should also test several different architectures, methods and hyperparameters, and describe/analyze what worked well and what didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class defines a simple convolution block\n",
    "# A convolution is followed by a non-linearity and a maxpooling\n",
    "class SimpleBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleBlock, self).__init__()\n",
    "        # Nonlinearities and max pooling\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpooling_layer = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        # Convolution Layers \n",
    "        self.convolution_layer_1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size = 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpooling_layer(x)\n",
    "        return x\n",
    "        \n",
    "# Model Decleration\n",
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, block):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolution Layers\n",
    "        self.convolution_layer_1 = block(in_channels= 3, out_channels = 8)\n",
    "        self.convolution_layer_2 = block(8, 16)\n",
    "        self.convolution_layer_3 = block(16, 32)\n",
    "        self.convolution_layer_4 = block(32, 64)\n",
    "        self.convolution_layer_5 = block(64, 128)\n",
    "        # Linear layer for classification\n",
    "        self.fully_connected_layer = torch.nn.Linear(in_features = 1152, out_features = 14)\n",
    "        # Sigmoid to squash between 0 and 1\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.convolution_layer_2(x)\n",
    "        x = self.convolution_layer_3(x)\n",
    "        x = self.convolution_layer_4(x)\n",
    "        x = self.convolution_layer_5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Model Training\n",
    "# Get data loaders\n",
    "b_size = 15\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_ex1, shuffle = True, batch_size = b_size, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset_ex1, batch_size = b_size, num_workers = 8)\n",
    "\n",
    "# Instantiate my_model\n",
    "# Send model to GPU\n",
    "my_model = ConvNet(SimpleBlock)\n",
    "my_model = my_model.cuda()\n",
    "\n",
    "# Print number of parameters\n",
    "print('Number of Parameters: ' + str(count_number_parameters(my_model)))\n",
    "\n",
    "# Define Loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training\n",
    "val_scores = []\n",
    "train_scores = []\n",
    "number_of_epochs = 10\n",
    "target_score = 0.67\n",
    "best_score = 0\n",
    "best_model = copy.deepcopy(my_model)\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    \n",
    "    # Toggle to training mode\n",
    "    my_model.train()\n",
    "\n",
    "    losses = []\n",
    "    for images, targets in train_loader:\n",
    "        # Zero out optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        # Get model prediction\n",
    "        out = my_model(images)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, targets)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track losss\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # Output mean loss for this epoch\n",
    "    print('Loss: ' + str(np.mean(losses)))\n",
    "    \n",
    "    # Get training data accuracy\n",
    "    train_score = get_score_model_chestxray_binary_model(my_model, train_loader)\n",
    "    mean_train_score = np.mean(train_score)\n",
    "    print('Trainig Score: ' + str(mean_train_score))\n",
    "    train_scores.append(mean_train_score)\n",
    "    \n",
    "    # Get validation data accuracy\n",
    "    val_score = get_score_model_chestxray_binary_model(my_model, val_loader)\n",
    "    mean_val_score = np.mean(val_score)\n",
    "    print('Validation Score: ' + str(mean_val_score))\n",
    "    val_scores.append(mean_val_score)\n",
    "    \n",
    "    # Save best model\n",
    "    if mean_val_score > target_score and mean_val_score > best_score:\n",
    "        best_score = mean_val_score\n",
    "        best_model = copy.deepcopy(my_model)\n",
    "        print('New Best Model Saved!')\n",
    "    \n",
    "# Plot Training and Validation AUC Score vs Epoch Number\n",
    "plt.plot(range(number_of_epochs), train_scores, 'b', range(number_of_epochs), val_scores, 'r')\n",
    "plt.title('AUC Scores For Question 1.2')\n",
    "plt.legend(['Training Data', 'Validation Data'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions on Test Dataset Using my model\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_ex1, batch_size = b_size, num_workers = 8)\n",
    "auc_score_test = get_score_model_chestxray_binary_model(best_model, test_loader)\n",
    "print(join_str_array_to_labels(auc_score_test, test_dataset_ex1.get_labels_name()))\n",
    "\n",
    "print('\\nMax Score: ' + str(max(auc_score_test)))\n",
    "print('Min Score: ' + str(min(auc_score_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for Question 1.2\n",
    "The model I designed has 288,990 parametrs. It is created by stacking convolution layers, there are five convolution layers total. The convolution layers are comprised of a convolution function, a non-lineraity (relu), and a max-pooling layer; in the analysis section I refer to the as the simple convolution block or simple block. The kernel size for the convoluation layer is five. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for Question 1.2\n",
    "For the convolution layer I tried kernel sizes of three, five, and seven. A kernel size of five got the best AUC score for the task. I also tried creating a convolution block that had a convolution layer, a relu layer, a convolution layer, a relu layer, and then the max-pooling layer. This convolution block performed worse than the simple block for all kernel sizes. I also tried mixing and matching the kernel sizes for the convolution block with multiple convolution layers; it did not improve. \n",
    "\n",
    "Training of my model with the simple block was slow so I tried to increase the learning rate. This reduced the AUC score for both training and validation data. I still used the BCELoss and Adam optimizer because that gave me the best results in question 2.1 and for the reasons explalined in the explanation section for that question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: RSNA Pneumonia Detection Challenge\n",
    "**(44 points total)**\n",
    "\n",
    "In this exercise we will be using a dataset from Kaggle. Kaggle is a website that hosts machine learning competitions and datasets, and is a great resource for finding interesting projects for practicing deep learning concepts. You will have to create a Kaggle account to access the dataset for this exercise. You will need to register for this Kaggle competition (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge), accept the terms, and get an API key for your account on Kaggle. To get this key, you should do:\n",
    "\n",
    "- click on your image on the upper right corner of a Kaggle webpage\n",
    "- click on \"My Account\"\n",
    "- click on the button \"Create New API Token\"\n",
    "- Save the key inside the json file somewhere.\n",
    "\n",
    "Below you will be asked for this key, so that a script can connect to the Kaggle databases and download the files to your system. \n",
    "\n",
    "The dataset for this exercise is a dataset which has images labeled as having pneumonia or not and, for each image with pneumonia, bounding boxes are provided to know where the evidence for pneumonia is in the image. The original dataset is evaluated as an object detection task, by mean average precision of bounding boxes (more details here, if you are curious: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge#evaluation ). Some famous models predict bounding boxes directly (https://pjreddie.com/darknet/yolo/, for example). However, we are going to simplify the task and convert the ground truth bounding boxes to a grid of binary labels, train a model using these modified labels, and use the AUC metric to evaluate them. \n",
    "\n",
    "**Important:** Please download the file **image_names_kaggle_pneumonia.csv** provided with the assignment and put it in the same directory as this notebook. If you are using Google Colaboratory, use the python command ```files.upload()``` below to upload the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the dataset and defining loading and processing  steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Google Colaboratory, use the next line to upload the image_names_kaggle_pneumonia.csv file\n",
    "# else put it in the same folder as this notebook\n",
    "if machine_being_used == 'colab':\n",
    "    files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting Kaggle username for the API connection\n",
    "print(\"Write your kaggle username:\")\n",
    "kaggle_username = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Kaggle API key for the API connection\n",
    "#check Exercise 2 for how to get this key\n",
    "print(\"Write your kaggle key:\")\n",
    "kaggle_key = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if pneumonia_dataset_folder!='/scratch/tmp/deep_learning_datasets_ECE_6960_013/kaggle_pneumonia':\n",
    "    #downloading the dataset\n",
    "    os.environ['KAGGLE_USERNAME']=kaggle_username\n",
    "    os.environ['KAGGLE_KEY']=kaggle_key\n",
    "    os.makedirs(pneumonia_dataset_folder, exist_ok=True)\n",
    "    !kaggle competitions download -c rsna-pneumonia-detection-challenge -p $pneumonia_dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pneumonia_dataset_folder!='/scratch/tmp/deep_learning_datasets_ECE_6960_013/kaggle_pneumonia':\n",
    "    #extracting the dataset\n",
    "    c1 = pneumonia_dataset_folder+'/stage_2_train_images.zip'\n",
    "    d1 = pneumonia_dataset_folder+'/stage_2_train_images'\n",
    "    e1 = pneumonia_dataset_folder+'/stage_2_train_labels.csv.zip'\n",
    "\n",
    "    !unzip -n $c1 -d $d1\n",
    "    !unzip -n $e1 -d $pneumonia_dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pytorch dataset class\n",
    "# it contains the data reading, indexing and preprocessing for the RSNA pneumonia localization dataset\n",
    "class RSNAPneumoniaDetectionDataset(Dataset):\n",
    "    \n",
    "    # defining a function that receives a list of bounding boxes and transform it \n",
    "    # into a spatial grid of positive and negative labels, positive labels corresponding to\n",
    "    # the bounding boxes locations\n",
    "    def get_grid(self, bounding_boxes):\n",
    "        #images of this dataset are 1024x1024 pixels\n",
    "        image_original_size = 1024\n",
    "        \n",
    "        \n",
    "        grid_size = self.grid_size\n",
    "        \n",
    "        # start by creating a grid with the same size as the original image\n",
    "        # since it is easy to know how each bounding box should be translated to 0/1 \n",
    "        # grid cells\n",
    "        # set as 1 cells inside bounding boxes, and 0 cells outside bounding boxes\n",
    "        this_grid = torch.zeros([1,1,image_original_size,image_original_size], dtype = torch.float)\n",
    "        for bounding_box in bounding_boxes:\n",
    "            if bounding_box[0]!=bounding_box[0]:\n",
    "                continue\n",
    "            y1 = int(bounding_box[1])\n",
    "            y2 = y1 + int(bounding_box[3])\n",
    "            x1 = int(bounding_box[0])\n",
    "            x2 = x1 + int(bounding_box[2])\n",
    "            this_grid[:,:,y1:y2, x1:x2] = 1.0\n",
    "        \n",
    "        #reduce the image to a size that is a multiple of the grid size, to be able to \n",
    "        # use average pooling with well defined kernel cells\n",
    "        first_resize_size = (image_original_size//self.grid_size)*self.grid_size\n",
    "        this_grid = torch.nn.functional.interpolate(this_grid, size = (first_resize_size, first_resize_size), mode = 'bilinear', align_corners = False)\n",
    "        this_grid = torch.nn.AvgPool2d(kernel_size = image_original_size//grid_size)(this_grid)\n",
    "        \n",
    "        #this_grid now should contain a number from 0 to 1 specifying how much of that particular cell\n",
    "        #is being occupied by a bounding box\n",
    "        \n",
    "        # only set as positive labeled the cells that had more than 50% of its area \n",
    "        # occupied by bounding boxes\n",
    "        this_grid = ((this_grid[0,:,:,:][:]>0.5)*1.0).float()\n",
    "        return this_grid\n",
    "    \n",
    "    #split can be 'train', 'val', and 'test'\n",
    "    def __init__(self, path_dataset_folder, grid_size, split = 'train'):\n",
    "        self.path_image_folder = path_dataset_folder + '/stage_2_train_images'\n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        #get the filenames of all images inside the dataset\n",
    "        all_images_list = !find $self.path_image_folder -type f -name \"*.dcm\" |sed 's#.*/##' | sed 's/\\.[^.]*$//'\n",
    "\n",
    "        #read the labels file\n",
    "        label_filename = path_dataset_folder + '/stage_2_train_labels.csv'\n",
    "        label_file = pd.read_csv(label_filename)\n",
    "        \n",
    "        # getting the list of all patient ids present in the dataset, to split into\n",
    "        # training, validation and testing by patient id\n",
    "        all_images_list =  pd.read_csv('image_names_kaggle_pneumonia.csv')['patientId'].values\n",
    "\n",
    "        all_images_list = pd.DataFrame(get_split(all_images_list, split), columns = ['patientId'])\n",
    "        \n",
    "        examples_to_use = pd.merge(all_images_list, label_file)\n",
    "        \n",
    "        # put all bounding boxes coordinates as a list of coordinates in a single column    \n",
    "        dataframe_with_listed_bounding_boxes = examples_to_use\n",
    "        dataframe_with_listed_bounding_boxes['x'] = dataframe_with_listed_bounding_boxes['x'].apply(lambda x: [x])\n",
    "        dataframe_with_listed_bounding_boxes['y'] = dataframe_with_listed_bounding_boxes['y'].apply(lambda x: [x])\n",
    "        dataframe_with_listed_bounding_boxes['width'] = dataframe_with_listed_bounding_boxes['width'].apply(lambda x: [x])\n",
    "        dataframe_with_listed_bounding_boxes['height'] = dataframe_with_listed_bounding_boxes['height'].apply(lambda x: [x])\n",
    "        dataframe_with_listed_bounding_boxes['bounding_boxes'] = dataframe_with_listed_bounding_boxes['x'] + \\\n",
    "                                                                dataframe_with_listed_bounding_boxes['y'] + \\\n",
    "                                                                dataframe_with_listed_bounding_boxes['width'] + \\\n",
    "                                                                dataframe_with_listed_bounding_boxes['height']\n",
    "        dataframe_with_listed_bounding_boxes = dataframe_with_listed_bounding_boxes[['patientId', 'bounding_boxes']]\n",
    "        \n",
    "        # Since bounding boxes for the same patient id are stored in more than one label line, \n",
    "        # group them by patient id and create a list of bounding boxes for each patient id\n",
    "        dataframe_with_listed_bounding_boxes = dataframe_with_listed_bounding_boxes.groupby('patientId')\n",
    "        dataframe_with_listed_bounding_boxes = dataframe_with_listed_bounding_boxes.aggregate(lambda x: tuple(x)).reset_index()\n",
    "        \n",
    "        # transform all lists of bounding boxes to grids\n",
    "        dataframe_with_listed_bounding_boxes['bounding_boxes'] = dataframe_with_listed_bounding_boxes['bounding_boxes'].apply(lambda x: self.get_grid(x))\n",
    "        \n",
    "        #join the tables with targets and grids\n",
    "        examples_to_use = examples_to_use[['patientId', 'Target']].drop_duplicates()\n",
    "        examples_to_use = pd.merge(examples_to_use, dataframe_with_listed_bounding_boxes)\n",
    "        assert(len(examples_to_use) == len(all_images_list))\n",
    "        \n",
    "        self.image_list = examples_to_use['patientId'].values\n",
    "        self.targets = examples_to_use['Target'].values\n",
    "        self.grids = examples_to_use['bounding_boxes'].values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #defining the transformations to do to the images before feeding it to the deep learning model\n",
    "        #these include cropping it to a square, resizing it to the usual ImageNet used size, transform it into a pytorch\n",
    "        # tensor, and normalizing it using the ImageNet dataset average and standard deviation per channel\n",
    "        set_of_transforms = transforms.Compose(\n",
    "        [CropBiggestCenteredInscribedSquare(),\n",
    "         transforms.Resize(224),\n",
    "         transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "        image_to_return = set_of_transforms(Image.fromarray(pydicom.dcmread(self.path_image_folder + '/' + self.image_list[index] + '.dcm').pixel_array))\n",
    "        \n",
    "        #the first element of the returned elements is a 3-channel image stored in a pytorch tensor\n",
    "        # the second element is a single binary label specifying the target label for that image, \n",
    "        # the third element is a 1-channel spatial grid specifying coarsely where in the image positive labels are present\n",
    "        return image_to_return, torch.FloatTensor(self.targets[index:index + 1]), torch.FloatTensor(self.grids[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the variables that you should use as datasets for Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the datasets to be used in exercise 2\n",
    "# this may take a few minutes\n",
    "train_dataset_ex2 = RSNAPneumoniaDetectionDataset(pneumonia_dataset_folder, grid_size  = 14)\n",
    "val_dataset_ex2 = RSNAPneumoniaDetectionDataset(pneumonia_dataset_folder, split = 'val', grid_size  = 14)\n",
    "test_dataset_ex2 = RSNAPneumoniaDetectionDataset(pneumonia_dataset_folder, split = 'test', grid_size  = 14)\n",
    "\n",
    "# if any of the following asserts fail, please contact the TA\n",
    "assert(len(train_dataset_ex2) == 16010)\n",
    "assert(len(val_dataset_ex2) == 5337)\n",
    "assert(len(test_dataset_ex2) == 5337)\n",
    "assert(sum(train_dataset_ex2.targets) == 3603)\n",
    "assert(sum(val_dataset_ex2.targets) == 1195)\n",
    "assert(np.sum([grid.numpy() for grid in train_dataset_ex2.grids]) == 81251)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short visualization of the resulting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show how unbalanced dataset is\n",
    "frequency = np.sum(train_dataset_ex2.targets, axis = 0)/len(train_dataset_ex2)\n",
    "                \n",
    "print('Percentage of positive examples for whole images: ' + '{:.2f}'.format(frequency*100) + '%')\n",
    "\n",
    "\n",
    "frequency = np.sum([grid.numpy() for grid in train_dataset_ex2.grids])/len(train_dataset_ex2)/14/14\n",
    "print('Percentage of positive examples for grid cells: ' + '{:.2f}'.format(frequency*100) + '%')\n",
    "\n",
    "def imresize(arr, size, resample):\n",
    "    return np.array(Image.fromarray(arr).resize(size, resample))\n",
    "\n",
    "def plot_grid_over_xray(example):\n",
    "    image = example[0].numpy()[0,:,:]\n",
    "    print('Label pneumonia: ' + str(example[1][0].cpu().numpy()))\n",
    "    max1 = np.max(image)\n",
    "    min1 = np.min(image)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow((image-min1)/(max1 - min1), cmap = 'gray')\n",
    "    ax.imshow(imresize(example[2].numpy()[0,:,:], (224, 224), resample  = Image.NEAREST), cmap='jet', alpha=0.3, resample = True)\n",
    "    plt.show()\n",
    "\n",
    "print('\\nVisualizing a few examples: ')\n",
    "#plot a few images from the dataset\n",
    "# reddish areas mean ones in the grid (pneumonia presence)\n",
    "#blueish areas mean zeros in the grid (pneumonia absence)\n",
    "plot_grid_over_xray(train_dataset_ex2[1])\n",
    "plot_grid_over_xray(train_dataset_ex2[10])\n",
    "plot_grid_over_xray(train_dataset_ex2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining scoring functions for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining one of the functions that calculate the AUC score for exercise 2\n",
    "# it calculates the score for a model that outputs a spatial grid of scores, for the task\n",
    "# of localizing where in an image there is evidence for pneumonia\n",
    "# one of the inputs of this function should be a model with which inference is made\n",
    "# the model should have one single score as output\n",
    "# the highest this score is, the highest the probability of this grid cell having evidence for pneumonia\n",
    "# the other input is a pytorch data loader for whatever set of data for which you want to get a score\n",
    "def get_score_model_pneumonia_location_model(model, data_loader):\n",
    "    #toggle model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    #turn off gradients since they will not be used here\n",
    "    # this is to make the inference faster\n",
    "    with torch.no_grad():\n",
    "        logits_predicted = np.zeros([0, 1])\n",
    "        targets = np.zeros([0,1])\n",
    "        #run through several batches, does inference for each and store inference results\n",
    "        # and store both target labels and inferenced scores \n",
    "        for image, target, grid in data_loader:\n",
    "            image = image.cuda()\n",
    "            logit_predicted = model(image)\n",
    "            # each grid cell target is considered a different example for calculating the score\n",
    "            # for that, all outputs and target are reshaped to have only one value in the second dimension\n",
    "            logits_predicted = np.concatenate((logits_predicted, logit_predicted.view([-1,1]).cpu().numpy()), axis = 0)\n",
    "            targets = np.concatenate((targets, grid.view([-1,1]).cpu().numpy()), axis = 0)\n",
    "    return auroc(logits_predicted[:,0], targets[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining one of the functions that calculate the AUC score for exercise 2\n",
    "# it calculates the score for a model that outputs a single score for the task of classifying\n",
    "# if an image contains evidence for pneumonia or not.\n",
    "# one of the inputs should be a model with which inference is made\n",
    "# the model should have one single score as output\n",
    "# the highest this score is, the highest the probability of this grid cell having evidence for pneumonia\n",
    "# the other input is a pytorch data loader for whatever set of data for which you want to get a score\n",
    "def get_score_model_pneumonia_binary_model(model, data_loader):\n",
    "    #toggle model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    #turn off gradients since they will not be used here\n",
    "    # this is to make the inference faster\n",
    "    with torch.no_grad():\n",
    "        logits_predicted = np.zeros([0,1])\n",
    "        targets = np.zeros([0,1])\n",
    "        \n",
    "        #run through several batches, does inference for each and store inference results\n",
    "        # and store both target labels and inferenced scores \n",
    "        for image, target, grid in data_loader:\n",
    "            image = image.cuda()\n",
    "            logit_predicted = model(image)\n",
    "            logits_predicted = np.concatenate((logits_predicted, logit_predicted.cpu().numpy()), axis = 0)\n",
    "            \n",
    "            targets = np.concatenate((targets, target.cpu().numpy()), axis = 0)\n",
    "    return auroc(logits_predicted, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining one of the functions that calculate the AUC score for exercise 2\n",
    "# it calculates the score for a model that outputs a grid of scores, but this grid is converted\n",
    "# to a single number to adapt this score to the binary task of saying if the whole image\n",
    "# has evidence for pneumonia or not\n",
    "# one of the inputs should be a model with which inference is made\n",
    "# the model should have one array with 196 (14x14) elements as output, and each output should be a score\n",
    "# the highest this score is, the highest the probability of this grid cell having evidence for pneumonia\n",
    "# the other input is a pytorch data loader for whatever set of data for which you want to get a score\n",
    "def get_score_model_pneumonia_binary_with_location_model(model, data_loader):\n",
    "    #toggle model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    #turn off gradients since they will not be used here\n",
    "    # this is to make the inference faster\n",
    "    with torch.no_grad():\n",
    "        logits_predicted = np.zeros([0,1])\n",
    "        targets = np.zeros([0,1])\n",
    "        \n",
    "        #run through several batches, does inference for each and store inference results\n",
    "        # and store both target labels and inferenced scores \n",
    "        for image, target, grid in data_loader:\n",
    "            image = image.cuda()\n",
    "            logit_predicted = model(image)\n",
    "            \n",
    "            # to convert a grid of labels to a single binary logit, we take the maximum logit \n",
    "            # in the grid. We do this since having only one grid cell labeled as positive means the whole\n",
    "            # image should be labeled as having pneumonia.\n",
    "            logits_predicted = np.concatenate((logits_predicted, torch.max(logit_predicted.view(logit_predicted.shape[0], -1),dim = 1)[0].view(-1,1).cpu().numpy()), axis = 0)\n",
    "            targets = np.concatenate((targets, target.cpu().numpy()), axis = 0)\n",
    "    return auroc(logits_predicted[:,0], targets[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2.1 (22 points)**: Modify the resnet18 model from PyTorch to output a flattened 14x14 grid, and train it on the pneumonia dataset to get an AUC of at least 0.97 in the validation set. The output of layer3 in the resnet18 model is already 14x14, so you should remove layer4 from the model and use the output of layer3. After getting the desired accuracy, test your best model on the test set. Select a few test examples for which your model got the locations correctly and a few examples with mistakes. Comment and show a visualization for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This class replaces layer four in the ResNet model\n",
    "# A convolution that reduces channel only\n",
    "class LayerFourReplacement(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LayerFourReplacement, self).__init__()\n",
    "        self.convolution_layer_1 = torch.nn.Conv2d(in_channels = 256, out_channels = 1, kernel_size=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "# Defint batch size\n",
    "b_size = 15\n",
    "# Get data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_ex2, shuffle = True, batch_size = b_size, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset_ex2, batch_size = b_size, num_workers = 8)\n",
    "\n",
    "# Get resnet model \n",
    "# Send model to GPU\n",
    "resnet_model = models.resnet18(pretrained = True)\n",
    "resnet_model.layer4 = LayerFourReplacement()\n",
    "resnet_model.avgpool = torch.nn.Sequential()\n",
    "resnet_model.fc = torch.nn.Sequential()\n",
    "resnet_model = resnet_model.cuda()\n",
    "\n",
    "# Define Loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training\n",
    "val_scores = []\n",
    "train_scores = []\n",
    "number_of_epochs = 10\n",
    "target_score = 0.97\n",
    "best_score = 0\n",
    "best_model = copy.deepcopy(resnet_model)\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    \n",
    "    # Toggle to training mode\n",
    "    resnet_model.train()\n",
    "\n",
    "    losses = []\n",
    "    for images, targets, grids in train_loader:\n",
    "        # Zero out optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        grids = grids.cuda()\n",
    "        # Get model prediction\n",
    "        out = resnet_model(images)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, grids.view(grids.size(0), -1))\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track losss\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # Output mean loss for this epoch\n",
    "    print('Loss: ' + str(np.mean(losses)))\n",
    "    \n",
    "    # Get training data accuracy\n",
    "    train_score = get_score_model_pneumonia_location_model(resnet_model, train_loader)\n",
    "    mean_train_score = np.mean(train_score)\n",
    "    print('Trainig Score: ' + str(mean_train_score))\n",
    "    train_scores.append(mean_train_score)\n",
    "    \n",
    "    # Get validation data accuracy\n",
    "    val_score = get_score_model_pneumonia_location_model(resnet_model, val_loader)\n",
    "    mean_val_score = np.mean(val_score)\n",
    "    print('Validation Score: ' + str(mean_val_score))\n",
    "    val_scores.append(mean_val_score)\n",
    "    \n",
    "    # Save Best Model\n",
    "    if mean_val_score > target_score and mean_val_score > best_score:\n",
    "        best_score = mean_val_score\n",
    "        best_model = copy.deepcopy(resnet_model)\n",
    "        print('New Best Model Saved!')\n",
    "    \n",
    "# Plot Training and Validation AUC Score vs Epoch Number\n",
    "plt.plot(range(number_of_epochs), train_scores, 'b', range(number_of_epochs), val_scores, 'r')\n",
    "plt.title('AUC Scores Question 2.1')\n",
    "plt.legend(['Training Data', 'Validation Data'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Score for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions on Test Dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_ex2, batch_size = 15, num_workers = 8)\n",
    "auc_score_test = get_score_model_pneumonia_location_model(best_model, test_loader)\n",
    "print('Test AUC Score: ' + str(auc_score_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This class is used to hold a prediction and its ground truth\n",
    "class Prediction:\n",
    "    def __init__(self, loss, image, target, grid, logit):\n",
    "        super(Prediction, self).__init__()\n",
    "        self.loss = loss\n",
    "        self.image = image\n",
    "        self.target = target\n",
    "        self.grid = grid\n",
    "        self.logit = logit\n",
    "\n",
    "# New predictions are compared to the current\n",
    "# list of worst predictions and the list is updated accordingly\n",
    "def get_worst(current_worst, new_prediction, list_size = 3):\n",
    "    if len(current_worst) < list_size:\n",
    "        current_worst.append(new_prediction)\n",
    "    else:    \n",
    "        for worst in current_worst:\n",
    "            if new_prediction.loss > worst.loss :\n",
    "                current_worst[current_worst.index(worst)] = new_prediction\n",
    "                return current_worst\n",
    "    return current_worst\n",
    "\n",
    "# New predictions are compared to the current\n",
    "# list of best predictions and the list is updated accordingly\n",
    "def get_best(current_best, new_prediction, list_size = 3):\n",
    "    if len(current_best) < list_size:\n",
    "        current_best.append(new_prediction)\n",
    "    else:    \n",
    "        for best in current_best:\n",
    "            if new_prediction.loss < best.loss :\n",
    "                current_best[current_best.index(best)] = new_prediction\n",
    "                return current_best\n",
    "    return current_best    \n",
    "\n",
    "# Gets lists of three worst and three best predictions\n",
    "# Best is defined as those prediction with the smallest loss\n",
    "def get_examples(model, data_loader):\n",
    "    #toggle model to eval mode\n",
    "    model.eval()\n",
    "    three_worst = []\n",
    "    three_best = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        count = 0;\n",
    "        for image, target, grid in data_loader:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            grid = grid.cuda()\n",
    "            \n",
    "            logit_predicted = model(image)\n",
    "            loss = criterion(logit_predicted, grid.view(grid.size(0), -1))\n",
    "            \n",
    "            prediction = Prediction(loss, image.view(3, 224, 224), target, grid.view(1, 14, 14), logit_predicted.view(1, 14, 14))\n",
    "            three_worst = get_worst(three_worst, prediction)\n",
    "            three_best = get_best(three_best, prediction)\n",
    "\n",
    "    return three_worst, three_best\n",
    "\n",
    "# Plots the grid, predicted or ground truth, over the image\n",
    "def plot_grid_over_xray(image, target, grid):\n",
    "    image = image.cpu().numpy()[0,:,:]\n",
    "    max1 = np.max(image)\n",
    "    min1 = np.min(image)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow((image-min1)/(max1 - min1), cmap = 'gray')\n",
    "    ax.imshow(imresize(grid.cpu().numpy()[0,:,:], (224, 224), resample  = Image.NEAREST), cmap='jet', alpha=0.3, resample = True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Test loader that gets a single image at a time and compares it to ground truth,\n",
    "# This is used to find the best and worst predictions\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_ex2, shuffle = True, batch_size = 1, num_workers = 8)\n",
    "worst, best = get_examples(best_model, test_loader)\n",
    "\n",
    "# Display Images\n",
    "print('Examples of Good Predictions')\n",
    "for i, b in enumerate(best):\n",
    "    print('Example ' + str(i) + ':')\n",
    "    print('Ground Truth')\n",
    "    plot_grid_over_xray(b.image, b.target, b.grid)\n",
    "    print('Prediction')\n",
    "    plot_grid_over_xray(b.image, b.target, b.logit)\n",
    "\n",
    "print('Examples of Poor Predictions')\n",
    "for i, w in enumerate(worst):\n",
    "    print('Example ' + str(i) + ':')\n",
    "    print('Ground Truth')\n",
    "    plot_grid_over_xray(w.image, w.target, w.grid)\n",
    "    print('Prediction')\n",
    "    plot_grid_over_xray(w.image, w.target, w.logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for Question 2.1\n",
    "Above are the visualziations for my three best and three worst test set prediction. In the three best predictions the patient does not have pneumonia. In the three worst predictions the patient does have pneumonia. In the worst case the prediction boxes are present, however there are lots of light blue and green boxes, which correlate with values less than one. The boxes in the ground truth images are dark orange which correlates with the value 1. It appears that in these images the model is returning grids with a low probability for cancer in the correct location when it should be returning a high probability in the same location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of parameters for Question 2.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count_number_parameters(best_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 2.2 (22 points)**: Modify the resnet18 model from PyTorch to have a single output and the same number of parameters of your model in question 2.1. For training this model, you are only allowed to use the pneumonia binary target for the whole image as ground truth, and you are not allowed to use the grid target. You should be able to achieve an AUC of at least 0.865.\n",
    "\n",
    "Also train a model just like the one from question 2.1, this time validating with a score for the binary task of presence or absence of pneumonia on an image. This score is calculated by the function ```get_score_model_pneumonia_binary_with_location_model```. When converting from a grid to a single output, this function considers that the probability of an image having pneumonia is the maximum probability over the grid.\n",
    "\n",
    "Compare both models on their scores for the binary task. Analyze why you got these results. Test your best model for the binary task on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary with Single Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This class replaces layer four in the ResNet model\n",
    "# A convolution that reduces channel only\n",
    "class LayerFourReplacement(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LayerFourReplacement, self).__init__()\n",
    "        self.convolution_layer_1 = torch.nn.Conv2d(in_channels = 256, out_channels = 1, kernel_size=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# This class replaces the fully connected layer in the resnet model\n",
    "# It takes the max value for the grid\n",
    "class FullyConnectedReplacement(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedReplacement, self).__init__()\n",
    "               \n",
    "    def forward(self, x):\n",
    "        x = torch.max(x, dim = 1)\n",
    "        x = x[0]\n",
    "        x = x.view(-1, 1)\n",
    "        return x\n",
    "    \n",
    "# Resnet - binary target\n",
    "# Create data loaders for data\n",
    "b_size = 15\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_ex2, shuffle = True, batch_size = b_size, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset_ex2, batch_size = b_size, num_workers = 8)\n",
    "\n",
    "# Get resnet model and change the output features to 14\n",
    "# Send model to GPU\n",
    "resnet_model = models.resnet18(pretrained = True)\n",
    "resnet_model.layer4 = LayerFourReplacement()\n",
    "resnet_model.avgpool = torch.nn.Sequential()\n",
    "resnet_model.fc = FullyConnectedReplacement()\n",
    "resnet_model = resnet_model.cuda()\n",
    "print('Number of Parameters for second part Q 2.2 Model: ' + str(count_number_parameters(resnet_model)))\n",
    "\n",
    "# Define Loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training\n",
    "val_scores = []\n",
    "train_scores = []\n",
    "number_of_epochs = 10\n",
    "target_score = 0.865\n",
    "best_score = 0\n",
    "best_model = copy.deepcopy(resnet_model)\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    \n",
    "    # Toggle to training mode\n",
    "    resnet_model.train()\n",
    "\n",
    "    losses = []\n",
    "    for images, targets, grids in train_loader:\n",
    "        # Zero out optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        grids = grids.cuda()\n",
    "        \n",
    "        # Get model output\n",
    "        out = resnet_model(images)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, targets)\n",
    "        \n",
    "        # Backpropigation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losss\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # Output mean loss for this epoch\n",
    "    print('Loss: ' + str(np.mean(losses)))\n",
    "    \n",
    "    # Training Accuracy\n",
    "    train_score = get_score_model_pneumonia_binary_model(resnet_model, train_loader)\n",
    "    mean_train_score = np.mean(train_score)\n",
    "    print('Trainig Score: ' + str(mean_train_score))\n",
    "    train_scores.append(mean_train_score)\n",
    "    \n",
    "    # Validation Accuracy\n",
    "    val_score = get_score_model_pneumonia_binary_model(resnet_model, val_loader)\n",
    "    mean_val_score = np.mean(val_score)\n",
    "    print('Validation Score: ' + str(mean_val_score))\n",
    "    val_scores.append(mean_val_score)\n",
    "    \n",
    "    # Save Best Model\n",
    "    if mean_val_score > target_score and mean_val_score > best_score:\n",
    "        best_score = mean_val_score\n",
    "        best_model = copy.deepcopy(resnet_model)\n",
    "        print('New Best Model Saved!')\n",
    "    \n",
    "# Plot Training and Validation AUC Score vs Epoch Number\n",
    "plt.plot(range(number_of_epochs), train_scores, 'b', range(number_of_epochs), val_scores, 'r')\n",
    "plt.title('AUC Scores for Question 2.2 Binary Output Only')\n",
    "plt.legend(['Training Data', 'Validation Data'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Using Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This class replaces layer four in the ResNet model\n",
    "# A convolution that reduces channel only\n",
    "class LayerFourReplacement(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LayerFourReplacement, self).__init__()\n",
    "        self.convolution_layer_1 = torch.nn.Conv2d(in_channels = 256, out_channels = 1, kernel_size=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "# Defint batch size\n",
    "b_size = 15\n",
    "# Get data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_ex2, shuffle = True, batch_size = b_size, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset_ex2, batch_size = b_size, num_workers = 8)\n",
    "\n",
    "# Get resnet model \n",
    "# Send model to GPU\n",
    "resnet_model = models.resnet18(pretrained = True)\n",
    "resnet_model.layer4 = LayerFourReplacement()\n",
    "resnet_model.avgpool = torch.nn.Sequential()\n",
    "resnet_model.fc = torch.nn.Sequential()\n",
    "resnet_model = resnet_model.cuda()\n",
    "\n",
    "# Define Loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training\n",
    "val_scores = []\n",
    "train_scores = []\n",
    "number_of_epochs = 10\n",
    "target_score = 0.865\n",
    "best_score = 0\n",
    "best_model = copy.deepcopy(resnet_model)\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    \n",
    "    # Toggle to training mode\n",
    "    resnet_model.train()\n",
    "\n",
    "    losses = []\n",
    "    for images, targets, grids in train_loader:\n",
    "        # Zero out optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        grids = grids.cuda()\n",
    "        # Get model prediction\n",
    "        out = resnet_model(images)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, grids.view(grids.size(0), -1))\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track losss\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # Output mean loss for this epoch\n",
    "    print('Loss: ' + str(np.mean(losses)))\n",
    "    \n",
    "    # Get training data accuracy\n",
    "    train_score = get_score_model_pneumonia_binary_with_location_model(resnet_model, train_loader)\n",
    "    mean_train_score = np.mean(train_score)\n",
    "    print('Trainig Score: ' + str(mean_train_score))\n",
    "    train_scores.append(mean_train_score)\n",
    "    \n",
    "    # Get validation data accuracy\n",
    "    val_score = get_score_model_pneumonia_binary_with_location_model(resnet_model, val_loader)\n",
    "    mean_val_score = np.mean(val_score)\n",
    "    print('Validation Score: ' + str(mean_val_score))\n",
    "    val_scores.append(mean_val_score)\n",
    "    \n",
    "    # Save Best Model\n",
    "    if mean_val_score > target_score and mean_val_score > best_score:\n",
    "        best_score = mean_val_score\n",
    "        best_model = copy.deepcopy(resnet_model)\n",
    "        print('New Best Model Saved!')\n",
    "    \n",
    "# Plot Training and Validation AUC Score vs Epoch Number\n",
    "plt.plot(range(number_of_epochs), train_scores, 'b', range(number_of_epochs), val_scores, 'r')\n",
    "plt.title('AUC Scores for Question 2.2 Binary with Location')\n",
    "plt.legend(['Training Data', 'Validation Data'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Question 2.2\n",
    "The model that retained location did better than the the model that only used the output. Only by ##%. \n",
    "* Similar because I took the max as the final layer\n",
    "* location better because it retains...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Score for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions on Test Dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_ex2, batch_size = 15, num_workers = 8)\n",
    "auc_score_test = get_score_model_pneumonia_binary_with_location_model(best_model, test_loader)\n",
    "print('Test AUC Score: ' + str(auc_score_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dir",
   "language": "python",
   "name": "env_dir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
